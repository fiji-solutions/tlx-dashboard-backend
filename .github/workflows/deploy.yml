name: Deploy TLX Dashboard Backend

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  AWS_REGION: eu-central-1
  ECR_REPOSITORY: fiji-cors-anywhere

jobs:
  build:
    name: Build and Push Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.build-image.outputs.image-tag }}
      image-uri: ${{ steps.build-image.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Build, tag, and push ARM64 image
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: tlx-dashboard-backend-${{ github.sha }}
      run: |
        # Build and push with commit SHA
        docker buildx build \
          --platform linux/arm64 \
          --push \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
          -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
          .
        
        echo "image-tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
        echo "image-uri=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment: staging
    env:
      ENVIRONMENT: staging
      NAMESPACE: tlx-dashboard-staging
      CLUSTER_NAME: fiji-staging-cluster
      DOMAIN: staging.api.finance.fijisolutions.net
      REPLICAS: 1
      MIN_REPLICAS: 1
      MAX_REPLICAS: 3
      ALB_GROUP_NAME: staging-shared-alb
      FLASK_ENV: development
      FLASK_DEBUG: "True"
      IMAGE: ${{ needs.build.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure kubectl for EKS
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create namespace if not exists
      run: |
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

    - name: Substitute environment variables in Kubernetes manifests
      run: |
        # Set staging-specific secrets
        export DB_HOST="${{ secrets.STAGING_DB_HOST }}"
        export DB_NAME="${{ secrets.STAGING_DB_NAME }}"
        export DB_USER="${{ secrets.STAGING_DB_USER }}"
        export DB_PASSWORD="${{ secrets.STAGING_DB_PASSWORD }}"
        export DB_PORT="${{ secrets.STAGING_DB_PORT }}"
        export SECRET_PASSWORD="${{ secrets.STAGING_SECRET_PASSWORD }}"
        export SECRET_PASSWORD2="${{ secrets.STAGING_SECRET_PASSWORD2 }}"
        export COGNITO_REGION="${{ secrets.STAGING_COGNITO_REGION }}"
        export COGNITO_USERPOOL_ID="${{ secrets.STAGING_COGNITO_USERPOOL_ID }}"
        export COGNITO_APP_CLIENT_ID="${{ secrets.STAGING_COGNITO_APP_CLIENT_ID }}"
        export CERTIFICATE_ARN="${{ secrets.STAGING_CERTIFICATE_ARN }}"
        export COINGECKO_API_KEY="${{ secrets.STAGING_COINGECKO_API_KEY }}"
        export SMTP_SENDER_EMAIL="${{ secrets.STAGING_SMTP_SENDER_EMAIL }}"
        export SMTP_RECEIVER_EMAIL="${{ secrets.STAGING_SMTP_RECEIVER_EMAIL }}"
        export SMTP_CC_EMAILS="${{ secrets.STAGING_SMTP_CC_EMAILS }}"
        export SMTP_USER="${{ secrets.STAGING_SMTP_USER }}"
        export SMTP_PASSWORD="${{ secrets.STAGING_SMTP_PASSWORD }}"
        
        # Substitute variables in manifest files
        envsubst < k8s/deployment.yaml > k8s/deployment-applied.yaml
        envsubst < k8s/service.yaml > k8s/service-applied.yaml
        envsubst < k8s/ingress.yaml > k8s/ingress-applied.yaml
        envsubst < k8s/cronjobs.yaml > k8s/cronjobs-applied.yaml

    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/deployment-applied.yaml
        kubectl apply -f k8s/service-applied.yaml
        kubectl apply -f k8s/ingress-applied.yaml
        kubectl apply -f k8s/cronjobs-applied.yaml

    - name: Wait for rollout to complete
      run: |
        kubectl rollout status deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=600s

    - name: Verify deployment
      run: |
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend
        # Wait for deployment to be ready instead of individual pods
        kubectl wait --for=condition=available deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=300s
        # Verify we have running pods (not terminating)
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend --field-selector=status.phase=Running

    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f k8s/*-applied.yaml

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production'
    environment: production
    env:
      ENVIRONMENT: production
      NAMESPACE: tlx-dashboard-production
      CLUSTER_NAME: fiji-prod-cluster
      DOMAIN: api.finance.fijisolutions.net
      REPLICAS: 2
      MIN_REPLICAS: 2
      MAX_REPLICAS: 10
      ALB_GROUP_NAME: production-shared-alb
      FLASK_ENV: production
      FLASK_DEBUG: "False"
      IMAGE: ${{ needs.build.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure kubectl for EKS
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create namespace if not exists
      run: |
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

    - name: Substitute environment variables in Kubernetes manifests
      run: |
        # Set production-specific secrets
        export DB_HOST="${{ secrets.PROD_DB_HOST }}"
        export DB_NAME="${{ secrets.PROD_DB_NAME }}"
        export DB_USER="${{ secrets.PROD_DB_USER }}"
        export DB_PASSWORD="${{ secrets.PROD_DB_PASSWORD }}"
        export DB_PORT="${{ secrets.PROD_DB_PORT }}"
        export SECRET_PASSWORD="${{ secrets.PROD_SECRET_PASSWORD }}"
        export SECRET_PASSWORD2="${{ secrets.PROD_SECRET_PASSWORD2 }}"
        export COGNITO_REGION="${{ secrets.PROD_COGNITO_REGION }}"
        export COGNITO_USERPOOL_ID="${{ secrets.PROD_COGNITO_USERPOOL_ID }}"
        export COGNITO_APP_CLIENT_ID="${{ secrets.PROD_COGNITO_APP_CLIENT_ID }}"
        export CERTIFICATE_ARN="${{ secrets.PROD_CERTIFICATE_ARN }}"
        export COINGECKO_API_KEY="${{ secrets.PROD_COINGECKO_API_KEY }}"
        export SMTP_SENDER_EMAIL="${{ secrets.PROD_SMTP_SENDER_EMAIL }}"
        export SMTP_RECEIVER_EMAIL="${{ secrets.PROD_SMTP_RECEIVER_EMAIL }}"
        export SMTP_CC_EMAILS="${{ secrets.PROD_SMTP_CC_EMAILS }}"
        export SMTP_USER="${{ secrets.PROD_SMTP_USER }}"
        export SMTP_PASSWORD="${{ secrets.PROD_SMTP_PASSWORD }}"
        
        # Substitute variables in manifest files
        envsubst < k8s/deployment.yaml > k8s/deployment-applied.yaml
        envsubst < k8s/service.yaml > k8s/service-applied.yaml
        envsubst < k8s/ingress.yaml > k8s/ingress-applied.yaml
        envsubst < k8s/cronjobs.yaml > k8s/cronjobs-applied.yaml

    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/deployment-applied.yaml
        kubectl apply -f k8s/service-applied.yaml
        kubectl apply -f k8s/ingress-applied.yaml
        kubectl apply -f k8s/cronjobs-applied.yaml

    - name: Wait for rollout to complete
      run: |
        kubectl rollout status deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=600s

    - name: Verify deployment
      run: |
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend
        # Wait for deployment to be ready instead of individual pods
        kubectl wait --for=condition=available deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=300s
        # Verify we have running pods (not terminating)
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend --field-selector=status.phase=Running

    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f k8s/*-applied.yaml