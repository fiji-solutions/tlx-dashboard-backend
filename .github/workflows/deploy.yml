name: Deploy TLX Dashboard Backend

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  AWS_REGION: eu-central-1
  ECR_REPOSITORY: fiji-cors-anywhere

jobs:
  build:
    name: Build and Push Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.build-image.outputs.image-tag }}
      image-uri: ${{ steps.build-image.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build and push Docker image
      id: build-image
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/arm64
        push: true
        tags: 735010339085.dkr.ecr.eu-central-1.amazonaws.com/${{ env.ECR_REPOSITORY }}:tlx-dashboard-backend-${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        labels: |
          org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
          org.opencontainers.image.revision=${{ github.sha }}
          org.opencontainers.image.created=${{ github.event.head_commit.timestamp }}

    - name: Set outputs
      run: |
        IMAGE_TAG=tlx-dashboard-backend-${{ github.sha }}
        echo "image-tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
        echo "image-uri=735010339085.dkr.ecr.eu-central-1.amazonaws.com/${{ env.ECR_REPOSITORY }}:$IMAGE_TAG" >> $GITHUB_OUTPUT

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment: staging
    env:
      ENVIRONMENT: staging
      NAMESPACE: tlx-dashboard-staging
      CLUSTER_NAME: fiji-staging-cluster
      DOMAIN: staging.api.finance.fijisolutions.net
      REPLICAS: 1
      MIN_REPLICAS: 1
      MAX_REPLICAS: 3
      ALB_GROUP_NAME: fiji-staging-alb
      FLASK_ENV: development
      FLASK_DEBUG: "True"
      IMAGE: ${{ needs.build.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure kubectl for EKS
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create namespace if not exists
      run: |
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

    - name: Substitute environment variables in Kubernetes manifests
      run: |
        # Set staging-specific secrets
        export DB_HOST="${{ secrets.STAGING_DB_HOST }}"
        export DB_NAME="${{ secrets.STAGING_DB_NAME }}"
        export DB_USER="${{ secrets.STAGING_DB_USER }}"
        export DB_PASSWORD="${{ secrets.STAGING_DB_PASSWORD }}"
        export DB_PORT="${{ secrets.STAGING_DB_PORT }}"
        export SECRET_PASSWORD="${{ secrets.STAGING_SECRET_PASSWORD }}"
        export SECRET_PASSWORD2="${{ secrets.STAGING_SECRET_PASSWORD2 }}"
        export COGNITO_REGION="${{ secrets.STAGING_COGNITO_REGION }}"
        export COGNITO_USERPOOL_ID="${{ secrets.STAGING_COGNITO_USERPOOL_ID }}"
        export COGNITO_APP_CLIENT_ID="${{ secrets.STAGING_COGNITO_APP_CLIENT_ID }}"
        export CERTIFICATE_ARN="${{ secrets.STAGING_CERTIFICATE_ARN }}"
        
        # Substitute variables in manifest files
        envsubst < k8s/deployment.yaml > k8s/deployment-applied.yaml
        envsubst < k8s/service.yaml > k8s/service-applied.yaml
        envsubst < k8s/ingress.yaml > k8s/ingress-applied.yaml

    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/deployment-applied.yaml
        kubectl apply -f k8s/service-applied.yaml
        kubectl apply -f k8s/ingress-applied.yaml

    - name: Wait for rollout to complete
      run: |
        kubectl rollout status deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=600s

    - name: Verify deployment
      run: |
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend
        kubectl wait --for=condition=ready pod -l app=tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=300s

    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f k8s/*-applied.yaml

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production'
    environment: production
    env:
      ENVIRONMENT: production
      NAMESPACE: tlx-dashboard-production
      CLUSTER_NAME: fiji-prod-cluster
      DOMAIN: api.finance.fijisolutions.net
      REPLICAS: 2
      MIN_REPLICAS: 2
      MAX_REPLICAS: 10
      ALB_GROUP_NAME: fiji-prod-alb
      FLASK_ENV: production
      FLASK_DEBUG: "False"
      IMAGE: ${{ needs.build.outputs.image-uri }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure kubectl for EKS
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

    - name: Create namespace if not exists
      run: |
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

    - name: Substitute environment variables in Kubernetes manifests
      run: |
        # Set production-specific secrets
        export DB_HOST="${{ secrets.PROD_DB_HOST }}"
        export DB_NAME="${{ secrets.PROD_DB_NAME }}"
        export DB_USER="${{ secrets.PROD_DB_USER }}"
        export DB_PASSWORD="${{ secrets.PROD_DB_PASSWORD }}"
        export DB_PORT="${{ secrets.PROD_DB_PORT }}"
        export SECRET_PASSWORD="${{ secrets.PROD_SECRET_PASSWORD }}"
        export SECRET_PASSWORD2="${{ secrets.PROD_SECRET_PASSWORD2 }}"
        export COGNITO_REGION="${{ secrets.PROD_COGNITO_REGION }}"
        export COGNITO_USERPOOL_ID="${{ secrets.PROD_COGNITO_USERPOOL_ID }}"
        export COGNITO_APP_CLIENT_ID="${{ secrets.PROD_COGNITO_APP_CLIENT_ID }}"
        export CERTIFICATE_ARN="${{ secrets.PROD_CERTIFICATE_ARN }}"
        
        # Substitute variables in manifest files
        envsubst < k8s/deployment.yaml > k8s/deployment-applied.yaml
        envsubst < k8s/service.yaml > k8s/service-applied.yaml
        envsubst < k8s/ingress.yaml > k8s/ingress-applied.yaml

    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/deployment-applied.yaml
        kubectl apply -f k8s/service-applied.yaml
        kubectl apply -f k8s/ingress-applied.yaml

    - name: Wait for rollout to complete
      run: |
        kubectl rollout status deployment/tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=600s

    - name: Verify deployment
      run: |
        kubectl get pods -n ${{ env.NAMESPACE }} -l app=tlx-dashboard-backend
        kubectl wait --for=condition=ready pod -l app=tlx-dashboard-backend -n ${{ env.NAMESPACE }} --timeout=300s

    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f k8s/*-applied.yaml